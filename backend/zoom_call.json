{"text": " and I should have changed the text, but that's fine. It was sent the request. And you will get this response from OpenAI just taking some time. And you can see in this case, the cloud was fastest. So we also have done the speed. Again, this changes based on your prompts and the type of question you ask. So in this case, it was cloud and we got the answer here.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.96, "text": " and I should have changed the text, but that's fine.", "tokens": [50364, 293, 286, 820, 362, 3105, 264, 2487, 11, 457, 300, 311, 2489, 13, 50512], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 1, "seek": 0, "start": 2.96, "end": 4.04, "text": " It was sent the request.", "tokens": [50512, 467, 390, 2279, 264, 5308, 13, 50566], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 2, "seek": 0, "start": 4.04, "end": 6.08, "text": " And you will get this response from OpenAI", "tokens": [50566, 400, 291, 486, 483, 341, 4134, 490, 7238, 48698, 50668], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 3, "seek": 0, "start": 6.08, "end": 7.04, "text": " just taking some time.", "tokens": [50668, 445, 1940, 512, 565, 13, 50716], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 4, "seek": 0, "start": 7.04, "end": 10.44, "text": " And you can see in this case, the cloud was fastest.", "tokens": [50716, 400, 291, 393, 536, 294, 341, 1389, 11, 264, 4588, 390, 14573, 13, 50886], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 5, "seek": 0, "start": 10.44, "end": 13.32, "text": " So we also have done the speed.", "tokens": [50886, 407, 321, 611, 362, 1096, 264, 3073, 13, 51030], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 6, "seek": 0, "start": 13.32, "end": 15.24, "text": " Again, this changes based on your prompts", "tokens": [51030, 3764, 11, 341, 2962, 2361, 322, 428, 41095, 51126], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 7, "seek": 0, "start": 15.24, "end": 17.32, "text": " and the type of question you ask.", "tokens": [51126, 293, 264, 2010, 295, 1168, 291, 1029, 13, 51230], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}, {"id": 8, "seek": 0, "start": 17.32, "end": 20.52, "text": " So in this case, it was cloud and we got the answer here.", "tokens": [51230, 407, 294, 341, 1389, 11, 309, 390, 4588, 293, 321, 658, 264, 1867, 510, 13, 51390], "temperature": 0.0, "avg_logprob": -0.255893743955172, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.28612634539604187}], "language": "en"}